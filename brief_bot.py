import os, json, time, threading, feedparser, requests, yfinance as yf, logging
from datetime import datetime, timedelta, timezone
from dotenv import load_dotenv
import telebot
from groq import Groq
from apscheduler.schedulers.background import BackgroundScheduler
import websocket

load_dotenv()

# â”€â”€ Logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

logging.basicConfig(
level=logging.INFO,
format=â€%(asctime)s [%(levelname)s] %(message)sâ€,
handlers=[logging.FileHandler(â€œbot.logâ€), logging.StreamHandler()]
)
log = logging.getLogger(**name**)

bot = telebot.TeleBot(os.getenv(â€œTELEGRAM_TOKENâ€))
client = Groq(api_key=os.getenv(â€œGROQ_API_KEYâ€))
CHANNEL_ID = os.getenv(â€œCHANNEL_IDâ€)

# â”€â”€ Feeds â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Geopolitics / OSINT â€” pure news RSS only, no newsletters

OSINT_FEEDS = [
â€œhttps://rss.app/feeds/RJmKz0o5CtyKOk5M.xmlâ€,
â€œhttps://rss.app/feeds/OAxXVuw3QaGC90A0.xmlâ€,
â€œhttp://feeds.feedburner.com/LongWarJournalâ€,
â€œhttps://thediplomat.com/feed/â€,
â€œhttps://warontherocks.com/feed/â€,
â€œhttps://news.google.com/rss/search?q=site%3Areuters.com&hl=en-US&gl=US&ceid=US%3Aenâ€,
â€œhttps://api.gdeltproject.org/api/v2/doc/doc?mode=artlist&format=rss&timespan=24h&query=(conflict+OR+military+OR+escalation+OR+protest+OR+strike+OR+geopolitics)â€,
â€œhttps://www.cfr.org/global-conflict-tracker/rssâ€,
â€œhttps://reliefweb.int/rss.xmlâ€,
]

# Markets / macro â€” pure news RSS only, no newsletters

MARKET_FEEDS = [
â€œhttps://news.google.com/rss/search?q=markets+macro+fed+rates+economy&hl=en-US&gl=US&ceid=US%3Aenâ€,
â€œhttps://news.google.com/rss/search?q=stock+market+S%26P+nasdaq+earnings&hl=en-US&gl=US&ceid=US%3Aenâ€,
â€œhttps://feeds.bloomberg.com/markets/news.rssâ€,
]

# AI / tech â€” pure news RSS only, no newsletters

TECH_FEEDS = [
â€œhttps://news.google.com/rss/search?q=artificial+intelligence+AI+tech+startups&hl=en-US&gl=US&ceid=US%3Aenâ€,
â€œhttps://techcrunch.com/feed/â€,
â€œhttps://www.theverge.com/rss/index.xmlâ€,
â€œhttps://venturebeat.com/feed/â€,
]

# Newsletters â€” only used for the newsletter section, never as news source

NEWSLETTER_FEEDS = [
(â€œThe Daily Degenâ€,   â€œhttps://thedailydegen.substack.com/feedâ€),
(â€œMacro Notesâ€,       â€œhttps://macronotes.substack.com/feedâ€),
(â€œDelphi Digitalâ€,    â€œhttps://delphidigital.substack.com/feedâ€),
(â€œArthur Hayesâ€,      â€œhttps://cryptohayes.medium.com/feedâ€),
(â€œChamathâ€,           â€œhttps://chamath.substack.com/feedâ€),
(â€œBenâ€™s Bitesâ€,       â€œhttps://www.bensbites.co/feedâ€),
(â€œThe Batch (DL.AI)â€, â€œhttps://www.deeplearning.ai/the-batch/feed/â€),
(â€œAlpha Signalâ€,      â€œhttps://alphasignal.substack.com/feedâ€),
(â€œTLDR AIâ€,           â€œhttps://tldr.tech/ai/feedâ€),
]

LAST_BRIEF_FILE = â€œlast_brief.txtâ€

# â”€â”€ Hyperliquid liquidations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

LIQ_THRESHOLDS = {â€œBTCâ€: 200000, â€œETHâ€: 200000, â€œSOLâ€: 100000}
DEFAULT_LIQ_THRESHOLD = 50000
METALS_THRESHOLD = 150000

liq_cache = []
liq_lock = threading.Lock()

def hyper_ws_listener():
backoff = 4

```
def on_message(ws, message):
    try:
        data = json.loads(message)
        if data.get("channel") == "liquidations":
            for liq in data.get("data", []):
                with liq_lock:
                    liq_cache.append(liq)
                    if len(liq_cache) > 200:
                        liq_cache.pop(0)
    except Exception as e:
        log.warning(f"Hyperliquid WS parse error: {e}")

def on_open(ws):
    ws.send(json.dumps({"method": "subscribe", "subscription": {"type": "liquidations"}}))
    log.info("Hyperliquid WS connected")

def on_error(ws, error):
    log.warning(f"Hyperliquid WS error: {error}")

while True:
    try:
        ws = websocket.WebSocketApp(
            "wss://api.hyperliquid.xyz/ws",
            on_message=on_message,
            on_open=on_open,
            on_error=on_error,
        )
        ws.run_forever(ping_interval=25)
        backoff = 4  # reset on clean disconnect
    except Exception as e:
        log.error(f"Hyperliquid WS crashed: {e}")
    log.info(f"Reconnecting Hyperliquid WS in {backoff}s...")
    time.sleep(backoff)
    backoff = min(backoff * 2, 120)
```

threading.Thread(target=hyper_ws_listener, daemon=True).start()

# â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def tg_send(chat_id, text, parse_mode=â€œMarkdownâ€):
â€œâ€â€œSend a message to Telegram, chunking if over 4000 chars.â€â€â€
MAX = 4000
chunks = [text[i:i + MAX] for i in range(0, len(text), MAX)]
for chunk in chunks:
try:
bot.send_message(chat_id, chunk, parse_mode=parse_mode)
time.sleep(0.3)
except Exception as e:
log.error(fâ€Telegram send failed: {e}â€)

def safe_parse_feed(url, max_entries=12):
try:
feed = feedparser.parse(url)
return feed.entries[:max_entries]
except Exception as e:
log.warning(fâ€Feed failed [{url}]: {e}â€)
return []

def safe_date(entry):
try:
if entry.get(â€œpublished_parsedâ€):
return datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
except Exception:
pass
return None

def get_last_brief_time():
try:
with open(LAST_BRIEF_FILE, â€œrâ€) as f:
dt = datetime.fromisoformat(f.read().strip())
if dt.tzinfo is None:
dt = dt.replace(tzinfo=timezone.utc)
return dt
except Exception:
return datetime.now(timezone.utc) - timedelta(days=1)

def save_last_brief_time():
tmp = LAST_BRIEF_FILE + â€œ.tmpâ€
with open(tmp, â€œwâ€) as f:
f.write(datetime.now(timezone.utc).isoformat())
os.replace(tmp, LAST_BRIEF_FILE)

# â”€â”€ News fetchers (RSS only) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _fetch_feed_list(feeds, max_per_feed=10, total=30):
articles = []
for url in feeds:
for entry in safe_parse_feed(url, max_entries=max_per_feed):
title = entry.get(â€œtitleâ€, â€œâ€).strip()[:160]
link = entry.get(â€œlinkâ€, â€œâ€)
if title:
articles.append(fâ€â€¢ {title} [link]({link})â€)
return â€œ\nâ€.join(articles[:total])

def get_osint_news():
return _fetch_feed_list(OSINT_FEEDS, max_per_feed=8, total=35) or â€œâ€¢ No major updatesâ€

def get_market_news():
return _fetch_feed_list(MARKET_FEEDS, max_per_feed=10, total=20) or â€œâ€¢ No market newsâ€

def get_tech_news():
return _fetch_feed_list(TECH_FEEDS, max_per_feed=10, total=20) or â€œâ€¢ No tech newsâ€

def get_newsletters_raw():
â€œâ€â€œReturns raw title + direct link for new newsletter posts since last brief.â€â€â€
last = get_last_brief_time()
lines = []
for name, url in NEWSLETTER_FEEDS:
for entry in safe_parse_feed(url, max_entries=5):
pub = safe_date(entry)
if pub and pub > last:
title = entry.get(â€œtitleâ€, â€œUntitledâ€).strip()
link = entry.get(â€œlinkâ€, â€œâ€)
lines.append(fâ€â€¢ *{name}* â€” [{title}]({link})â€)
return â€œ\nâ€.join(lines) if lines else â€œâ€¢ No new newsletters since last brief.â€

# â”€â”€ Market data (fetched directly, never passed through Groq) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def fetch_ticker(symbol):
try:
data = yf.Ticker(symbol).history(period=â€œ2dâ€)[â€œCloseâ€]
if len(data) < 2:
return symbol, None, None
change = ((data.iloc[-1] - data.iloc[-2]) / data.iloc[-2]) * 100
return symbol, data.iloc[-1], change
except Exception as e:
log.warning(fâ€yfinance failed [{symbol}]: {e}â€)
return symbol, None, None

def get_market_update():
tickers = {
â€œ^GSPCâ€:   â€œS&P 500â€,
â€œ^IXICâ€:   â€œNasdaqâ€,
â€œ^DJIâ€:    â€œDowâ€,
â€œNVDAâ€:    â€œNVDAâ€,
â€œTSLAâ€:    â€œTSLAâ€,
â€œAAPLâ€:    â€œAAPLâ€,
â€œBTC-USDâ€: â€œBTCâ€,
â€œETH-USDâ€: â€œETHâ€,
}
lines = []
for symbol, label in tickers.items():
_, price, change = fetch_ticker(symbol)
if price is not None:
emoji = â€œğŸŸ¢â€ if change > 0 else â€œğŸ”´â€
lines.append(fâ€â€¢ {label}: {price:.2f} ({change:+.1f}%) {emoji}â€)
else:
lines.append(fâ€â€¢ {label}: N/Aâ€)
return â€œ\nâ€.join(lines)

def get_commodities_vol():
tickers = {
â€œGC=Fâ€: â€œGoldâ€,
â€œCL=Fâ€: â€œCrude Oilâ€,
â€œNG=Fâ€: â€œNat Gasâ€,
â€œ^VIXâ€: â€œVIXâ€,
}
lines = []
for symbol, label in tickers.items():
_, price, change = fetch_ticker(symbol)
if price is not None:
emoji = â€œğŸŸ¢â€ if change > 0 else â€œğŸ”´â€
lines.append(fâ€â€¢ {label}: {price:.2f} ({change:+.1f}%) {emoji}â€)
else:
lines.append(fâ€â€¢ {label}: N/Aâ€)
return â€œ\nâ€.join(lines)

def get_fear_greed():
try:
d = requests.get(â€œhttps://api.alternative.me/fng/â€, timeout=8).json()[â€œdataâ€][0]
return fâ€{d[â€˜value_classificationâ€™]} ({d[â€˜valueâ€™]})â€
except Exception as e:
log.warning(fâ€Fear & Greed failed: {e}â€)
return â€œN/Aâ€

def get_economic_calendar():
today = datetime.now().strftime(â€%Y-%m-%dâ€)
try:
r = requests.get(
fâ€https://finnhub.io/api/v1/calendar/economic?from={today}&to={today}&token={os.getenv(â€˜FINNHUB_KEYâ€™)}â€,
timeout=8
).json()
high = [e for e in r.get(â€œeconomicCalendarâ€, []) if e.get(â€œimpactâ€) in (â€œhighâ€, â€œmediumâ€)]
if not high:
return â€œâ€¢ Quiet dayâ€
return â€œ\nâ€.join([fâ€â€¢ {e[â€˜timeâ€™]} {e[â€˜eventâ€™]} ({e.get(â€˜countryâ€™, â€˜â€™)})â€ for e in high[:6]])
except Exception as e:
log.warning(fâ€Economic calendar failed: {e}â€)
return â€œâ€¢ Quiet dayâ€

def get_hyperliquid_snapshot():
with liq_lock:
if not liq_cache:
return â€œâ€¢ Quiet â€” no significant liquidationsâ€
lines = []
for l in sorted(
liq_cache[-50:],
key=lambda x: float(x.get(â€œszâ€, 0)) * float(x.get(â€œpxâ€, 0)),
reverse=True
):
coin = l.get(â€œcoinâ€, â€œOTHERâ€)
sz = float(l.get(â€œszâ€, 0))
px = float(l.get(â€œpxâ€, 0))
ntl = sz * px
thresh = LIQ_THRESHOLDS.get(
coin,
METALS_THRESHOLD if â€œMETALâ€ in coin.upper() else DEFAULT_LIQ_THRESHOLD
)
if ntl > thresh:
side = l.get(â€œsideâ€, â€œâ€).upper()
direction = â€œğŸ”´ LONG liqâ€ if side in [â€œSELLâ€, â€œSâ€] else â€œğŸŸ¢ SHORT liqâ€
lines.append(fâ€â€¢ {coin} {sz:.4f} @ {px:.2f} ({direction}) ~${ntl:,.0f}â€)
return â€œ\nâ€.join(lines[:10]) if lines else â€œâ€¢ Quiet â€” no significant liquidationsâ€

# â”€â”€ Groq summarizer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def summarize(raw_data, mode=â€œallâ€):
â€œâ€â€
Groq only ever receives RSS headline data.
Structured market data (tickers, commodities, liqs, calendar, sentiment)
is NEVER passed here â€” it is appended directly by the bot after this call.
â€œâ€â€

```
if mode == "geo":
    prompt = f"""You are an intelligence analyst. Summarize the following geopolitical and conflict news headlines into concise, sharp bullets.
```

Rules:

- One distinct topic per bullet
- 1-2 sentences max per bullet
- Preserve source links in [link](url) format
- No market data, no tech news, no newsletter content
- Group by region where possible (Europe, Middle East, Asia, Americas)

Raw headlines:
{raw_data[:6000]}â€â€â€
max_tokens = 1000

```
elif mode == "market":
    prompt = f"""You are a macro analyst. Summarize the following market and macro news headlines into concise bullets.
```

Rules:

- One distinct topic per bullet
- 1-2 sentences max per bullet
- Preserve source links in [link](url) format
- Focus strictly on: rates, central banks, equities, crypto, commodities, economic data
- No geopolitics unless directly market-moving, no tech product news, no newsletter content

Raw headlines:
{raw_data[:6000]}â€â€â€
max_tokens = 1000

```
elif mode == "tech":
    prompt = f"""You are an AI and tech analyst. Summarize the following AI and tech news headlines into concise bullets.
```

Rules:

- One distinct topic per bullet
- 1-2 sentences max per bullet
- Preserve source links in [link](url) format
- Focus strictly on: AI models, research, startups, big tech, developer tools
- No market data, no geopolitics, no newsletter content

Raw headlines:
{raw_data[:6000]}â€â€â€
max_tokens = 1000

```
else:  # mode == "all" â€” only summarizes the three news sections
    prompt = f"""You are a sharp intelligence and market analyst. Summarize the headlines below into three clearly separated sections.
```

Rules:

- Only use the RSS headlines provided â€” do NOT reference or draw from newsletter content
- One distinct topic per bullet, 1-2 sentences max
- Preserve source links in [link](url) format where available
- Strictly separate the three sections â€” do not mix topics across them
- Group geopolitics by region where possible (Europe, Middle East, Asia, Americas)
- Do NOT include any section for newsletters, indicators, commodities, liquidations, or sentiment â€” those will be added separately

Output EXACTLY this structure (nothing else):

ğŸŒ *Geopolitics & Conflicts*
â€¢ bullet [link](url)

ğŸ“ˆ *Markets & Macro*
â€¢ bullet [link](url)

ğŸ¤– *AI & Tech*
â€¢ bullet [link](url)

Raw headlines:
{raw_data[:9000]}â€â€â€
max_tokens = 2000

```
for attempt in range(3):
    try:
        chat = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=max_tokens,
        )
        return chat.choices[0].message.content.strip()
    except Exception as e:
        log.warning(f"Groq attempt {attempt + 1} failed: {e}")
        time.sleep(3 * (attempt + 1))

log.error("Groq failed after 3 attempts, returning raw headlines")
return raw_data[:3500]
```

# â”€â”€ Brief builder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_and_send_brief(chat_id):
log.info(fâ€Building morning brief for {chat_id}â€)

```
# â”€â”€ Step 1: fetch RSS news for Groq (no newsletters, no structured data) â”€â”€â”€
osint     = get_osint_news()
mkt_news  = get_market_news()
tech_news = get_tech_news()

news_raw = f"""GEOPOLITICS HEADLINES:
```

{osint}

MARKET/MACRO HEADLINES:
{mkt_news}

AI/TECH HEADLINES:
{tech_news}â€â€â€

```
# â”€â”€ Step 2: fetch structured data directly â€” never touches Groq â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
indicators  = get_market_update()
commodities = get_commodities_vol()
hyper       = get_hyperliquid_snapshot()
econ        = get_economic_calendar()
fg          = get_fear_greed()
newsletters = get_newsletters_raw()

# â”€â”€ Step 3: Groq summarizes only the three news sections â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
news_summary = summarize(news_raw, mode="all")

# â”€â”€ Step 4: assemble full brief â€” structured data appended directly â”€â”€â”€â”€â”€â”€â”€â”€
date_str = datetime.now().strftime("%B %d, %Y %H:%M UTC")
full_message = (
    f"*Morning Brief â€” {date_str}*\n\n"
    f"{news_summary}\n\n"
    f"ğŸ“Š *Key Indicators*\n{indicators}\n\n"
    f"ğŸ›¢ *Commodities & Vol*\n{commodities}\n\n"
    f"ğŸ’¥ *Hyperliquid Liquidations*\n{hyper}\n\n"
    f"ğŸ“… *Economic Calendar*\n{econ}\n\n"
    f"ğŸ˜¨ *Sentiment:* {fg}\n\n"
    f"ğŸ“° *New Newsletters*\n{newsletters}"
)

tg_send(chat_id, full_message)
save_last_brief_time()
```

def send_scheduled_brief():
build_and_send_brief(CHANNEL_ID)

# â”€â”€ Commands â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@bot.message_handler(commands=[â€œhelpâ€])
def cmd_help(message):
text = (
â€œğŸ“‹ *Commands*\n\nâ€
â€œ/all â€” full morning brief\nâ€
â€œ/geo â€” geopolitics & conflicts\nâ€
â€œ/market â€” markets, macro, tickers & sentiment\nâ€
â€œ/tech â€” AI & tech news\nâ€
â€œ/liqs â€” Hyperliquid liquidation snapshot\nâ€
â€œ/help â€” show this menu\nâ€
)
tg_send(message.chat.id, text)

@bot.message_handler(commands=[â€œallâ€, â€œbriefâ€, â€œfullâ€])
def cmd_all(message):
tg_send(message.chat.id, â€œâ³ Building your morning briefâ€¦â€)
build_and_send_brief(message.chat.id)

@bot.message_handler(commands=[â€œgeoâ€, â€œgeopoliticsâ€])
def cmd_geo(message):
tg_send(message.chat.id, â€œâ³ Fetching geopoliticsâ€¦â€)
data = get_osint_news()
summary = summarize(data, mode=â€œgeoâ€)
tg_send(
message.chat.id,
fâ€ğŸŒ *Geopolitics & Conflicts â€” {datetime.now().strftime(â€™%H:%M UTCâ€™)}*\n\n{summary}â€
)

@bot.message_handler(commands=[â€œmarketâ€])
def cmd_market(message):
tg_send(message.chat.id, â€œâ³ Fetching marketsâ€¦â€)
news = get_market_news()
summary = summarize(news, mode=â€œmarketâ€)
indicators  = get_market_update()
commodities = get_commodities_vol()
fg          = get_fear_greed()
full = (
fâ€ğŸ“ˆ *Markets & Macro â€” {datetime.now().strftime(â€™%H:%M UTCâ€™)}*\n\nâ€
fâ€{summary}\n\nâ€
fâ€ğŸ“Š *Key Indicators*\n{indicators}\n\nâ€
fâ€ğŸ›¢ *Commodities & Vol*\n{commodities}\n\nâ€
fâ€ğŸ˜¨ *Sentiment:* {fg}â€
)
tg_send(message.chat.id, full)

@bot.message_handler(commands=[â€œtechâ€])
def cmd_tech(message):
tg_send(message.chat.id, â€œâ³ Fetching AI & techâ€¦â€)
data = get_tech_news()
summary = summarize(data, mode=â€œtechâ€)
tg_send(
message.chat.id,
fâ€ğŸ¤– *AI & Tech â€” {datetime.now().strftime(â€™%H:%M UTCâ€™)}*\n\n{summary}â€
)

@bot.message_handler(commands=[â€œliqsâ€])
def cmd_liqs(message):
snapshot = get_hyperliquid_snapshot()
tg_send(
message.chat.id,
fâ€ğŸ’¥ *Hyperliquid Snapshot â€” {datetime.now().strftime(â€™%H:%M UTCâ€™)}*\n\n{snapshot}â€
)

# â”€â”€ Scheduler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

scheduler = BackgroundScheduler(timezone=â€œEurope/Romeâ€)
scheduler.add_job(send_scheduled_brief, â€œcronâ€, hour=6, minute=0)
scheduler.add_job(send_scheduled_brief, â€œcronâ€, hour=19, minute=0)
scheduler.start()

log.info(â€œğŸš€ Coffee Brief bot STARTEDâ€)
bot.infinity_polling()
